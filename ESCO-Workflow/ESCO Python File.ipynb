{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 18:58:07,303 - INFO - Fetching ESCO data from https://raw.githubusercontent.com/Kyleinexile/IS-Repo/refs/heads/main/ESCO.json\n",
      "2025-03-27 18:58:08,218 - INFO - Retrieved 13939 ESCO entries\n",
      "2025-03-27 18:58:08,220 - INFO - Found 10715 skill/competence entries\n",
      "2025-03-27 18:58:08,221 - INFO - Processing batch 1/11: entries 0 to 999\n",
      "2025-03-27 18:58:08,243 - INFO - Processing batch 2/11: entries 1000 to 1999\n",
      "2025-03-27 18:58:08,252 - INFO - Processing batch 3/11: entries 2000 to 2999\n",
      "2025-03-27 18:58:08,262 - INFO - Processing batch 4/11: entries 3000 to 3999\n",
      "2025-03-27 18:58:08,272 - INFO - Processing batch 5/11: entries 4000 to 4999\n",
      "2025-03-27 18:58:08,281 - INFO - Processing batch 6/11: entries 5000 to 5999\n",
      "2025-03-27 18:58:08,290 - INFO - Processing batch 7/11: entries 6000 to 6999\n",
      "2025-03-27 18:58:08,300 - INFO - Processing batch 8/11: entries 7000 to 7999\n",
      "2025-03-27 18:58:08,309 - INFO - Processing batch 9/11: entries 8000 to 8999\n",
      "2025-03-27 18:58:08,317 - INFO - Processing batch 10/11: entries 9000 to 9999\n",
      "2025-03-27 18:58:08,328 - INFO - Processing batch 11/11: entries 10000 to 10714\n",
      "2025-03-27 18:58:08,335 - INFO - ESCO processing complete. Processed 10715 skills.\n",
      "2025-03-27 18:58:08,454 - INFO - Data saved to processed_data\\processed-esco-skills-2025-03-27-18-58-08.json\n",
      "2025-03-27 18:58:08,454 - INFO - Workflow completed successfully\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "ESCO Skills Data Processing Pipeline\n",
    "\n",
    "This script replicates the n8n workflow for processing ESCO skills data:\n",
    "1. Fetches raw ESCO data from GitHub\n",
    "2. Processes and extracts essential skill information\n",
    "3. Saves the processed data to a local file\n",
    "\n",
    "Author: Kyle Hall\n",
    "Date: March 2025\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import re\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"esco_processor.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def fetch_esco_data(url: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Fetch ESCO data from GitHub or other URL\n",
    "    \n",
    "    Args:\n",
    "        url: URL to the ESCO JSON data\n",
    "        \n",
    "    Returns:\n",
    "        List of ESCO entries as dictionaries\n",
    "    \"\"\"\n",
    "    logger.info(f\"Fetching ESCO data from {url}\")\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    data = json.loads(response.text)\n",
    "    logger.info(f\"Retrieved {len(data)} ESCO entries\")\n",
    "    return data\n",
    "\n",
    "def process_esco_skills(esco_data: List[Dict[str, Any]], batch_size: int = 1000) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Process ESCO data to extract skills information\n",
    "    \n",
    "    Args:\n",
    "        esco_data: Raw ESCO data from API\n",
    "        batch_size: Number of items to process in each batch\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing processed skills and metadata\n",
    "    \"\"\"\n",
    "    # Filter for skills\n",
    "    skill_entries = [entry for entry in esco_data if entry.get('skillType') == 'skill/competence']\n",
    "    logger.info(f\"Found {len(skill_entries)} skill/competence entries\")\n",
    "    \n",
    "    total_batches = (len(skill_entries) + batch_size - 1) // batch_size\n",
    "    \n",
    "    # Process in batches\n",
    "    processed_skills = []\n",
    "    for i in range(0, len(skill_entries), batch_size):\n",
    "        batch_end = min(i + batch_size, len(skill_entries))\n",
    "        logger.info(f\"Processing batch {i//batch_size + 1}/{total_batches}: entries {i} to {batch_end-1}\")\n",
    "        \n",
    "        batch = skill_entries[i:batch_end]\n",
    "        \n",
    "        # Process each skill in batch\n",
    "        for skill in batch:\n",
    "            try:\n",
    "                # Extract verb (first word of skill name)\n",
    "                skill_name = skill.get('skillName', '').strip().lower()\n",
    "                skill_name_words = re.split(r'\\s+', skill_name)\n",
    "                verb = skill_name_words[0] if skill_name_words else ''\n",
    "                \n",
    "                # Extract alternate labels\n",
    "                alt_labels_text = skill.get('alternateLabels', '')\n",
    "                alternate_labels = [label.strip() for label in alt_labels_text.split('\\n') if label.strip()]\n",
    "                \n",
    "                # Create search text\n",
    "                search_text = ' '.join([\n",
    "                    skill.get('skillName', ''),\n",
    "                    ' '.join(alternate_labels),\n",
    "                    skill.get('description', '')\n",
    "                ]).lower()\n",
    "                \n",
    "                # Extract keywords\n",
    "                all_words = re.split(r'\\s+', search_text)\n",
    "                common_words = ['and', 'or', 'the', 'a', 'an', 'in', 'on', 'at', 'to', 'for', 'with', 'by', 'of', 'such', 'as']\n",
    "                filtered_words = [word for word in all_words if word and len(word) > 3 and word not in common_words]\n",
    "                \n",
    "                # Count word frequencies\n",
    "                word_freq = {}\n",
    "                for word in filtered_words:\n",
    "                    word_freq[word] = word_freq.get(word, 0) + 1\n",
    "                \n",
    "                # Get top keywords\n",
    "                keywords = [word for word, _ in sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:20]]\n",
    "                \n",
    "                processed_skills.append({\n",
    "                    'skillId': skill.get('id', ''),\n",
    "                    'skillName': skill.get('skillName', ''),\n",
    "                    'description': skill.get('description', ''),\n",
    "                    'verb': verb,\n",
    "                    'alternateLabels': alternate_labels,\n",
    "                    'keywords': keywords,\n",
    "                    'searchText': search_text\n",
    "                })\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing skill '{skill.get('skillName', 'Unknown')}': {str(e)}\")\n",
    "    \n",
    "    logger.info(f\"ESCO processing complete. Processed {len(processed_skills)} skills.\")\n",
    "    \n",
    "    return {\n",
    "        'processedEscoSkills': processed_skills,\n",
    "        'metadata': {\n",
    "            'totalEntries': len(esco_data),\n",
    "            'processedSkills': len(processed_skills),\n",
    "            'processingDate': datetime.datetime.now().isoformat()\n",
    "        }\n",
    "    }\n",
    "\n",
    "def save_to_file(processed_data: Dict[str, Any], output_dir: str = '.', file_path: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Save processed data to a JSON file\n",
    "    \n",
    "    Args:\n",
    "        processed_data: The processed data to save\n",
    "        output_dir: Directory to save the file\n",
    "        file_path: Optional specific file path\n",
    "        \n",
    "    Returns:\n",
    "        Path to the saved file\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    if file_path is None:\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "        file_path = os.path.join(output_dir, f\"processed-esco-skills-{timestamp}.json\")\n",
    "    \n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(processed_data, f, indent=2)\n",
    "    \n",
    "    logger.info(f\"Data saved to {file_path}\")\n",
    "    return file_path\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main entry point for the script\"\"\"\n",
    "    # URL to ESCO data\n",
    "    url = \"https://raw.githubusercontent.com/Kyleinexile/IS-Repo/refs/heads/main/ESCO.json\"\n",
    "    output_dir = \"processed_data\"\n",
    "    \n",
    "    try:\n",
    "        # Fetch data\n",
    "        esco_data = fetch_esco_data(url)\n",
    "        \n",
    "        # Process data\n",
    "        processed_data = process_esco_skills(esco_data)\n",
    "        \n",
    "        # Save to file\n",
    "        save_to_file(processed_data, output_dir)\n",
    "        \n",
    "        logger.info(\"Workflow completed successfully\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in workflow: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
